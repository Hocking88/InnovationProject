{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35f8a196",
   "metadata": {},
   "source": [
    "\n",
    "# Malware Detection — Combined Dataset Training & Evaluation\n",
    "\n",
    "This notebook trains models on `data/EDA/Cleaned_combined_malware_dataset.csv` (PE header + process stats).  \n",
    "Target column: **`legitimate`** (1 = benign, 0 = malware).\n",
    "\n",
    "Models:\n",
    "- **Classification:** Logistic Regression (scaled), SVM RBF (scaled), Random Forest (constrained)\n",
    "- **Clustering:** K-Means (k=2), DBSCAN\n",
    "- **Outputs:** ROC curves (LR & SVM), RF feature importances, metrics table (`artifacts/classifier_metrics_combined.csv`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, classification_report, roc_curve, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = os.path.join(\"data\", \"EDA\", \"Cleaned_combined_malware_dataset.csv\")\n",
    "ART_DIR = os.path.join(\"artifacts\")\n",
    "PLOT_DIR = os.path.join(ART_DIR, \"plots\")\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Reading:\", DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Drop accidental unnamed columns\n",
    "drop_un = [c for c in df.columns if str(c).lower().startswith(\"unnamed\") or str(c).strip() == \"\"]\n",
    "if drop_un:\n",
    "    df = df.drop(columns=drop_un)\n",
    "    print(\"Dropped accidental columns:\", drop_un)\n",
    "\n",
    "if \"legitimate\" not in df.columns:\n",
    "    raise ValueError(\"Expected 'legitimate' column in combined dataset. Found: \" + str(list(df.columns)))\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns)[:10], \"...\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff121d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Features/labels\n",
    "X = df.drop(columns=[\"legitimate\"]).copy()\n",
    "y = df[\"legitimate\"].astype(int)\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scaled versions for LR/SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"| Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def report_classifier(name, y_true, y_pred, y_prob=None):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob) if y_prob is not None else float(\"nan\")\n",
    "    print(f\"Accuracy={acc:.5f}, Precision={prec:.5f}, Recall={rec:.5f}, F1={f1:.5f}, ROC AUC={auc:.5f}\")\n",
    "    return {\"model\": name, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"roc_auc\": auc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaaa664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression (scaled)\n",
    "logreg = LogisticRegression(max_iter=5000, solver=\"saga\", n_jobs=-1)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = logreg.predict(X_test_scaled)\n",
    "y_prob_lr = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "m_lr = report_classifier(\"Logistic Regression (scaled)\", y_test, y_pred_lr, y_prob_lr)\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob_lr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"LogReg ROC\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"roc_logreg_combined.png\"), dpi=160, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SVM RBF (scaled)\n",
    "svm = SVC(kernel=\"rbf\", probability=True, random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "y_prob_svm = svm.predict_proba(X_test_scaled)[:, 1]\n",
    "m_svm = report_classifier(\"SVM RBF (scaled)\", y_test, y_pred_svm, y_prob_svm)\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob_svm)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"SVM ROC\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - SVM (RBF)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"roc_svm_combined.png\"), dpi=160, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7899691",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Forest (constrained)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=15, min_samples_leaf=5, random_state=42, n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "m_rf = report_classifier(\"Random Forest (constrained)\", y_test, y_pred_rf, y_prob_rf)\n",
    "\n",
    "# Feature importances\n",
    "importances = rf.feature_importances_\n",
    "idx = np.argsort(importances)[::-1][:20]\n",
    "top_feats = [X.columns[i] for i in idx]\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.bar(range(len(idx)), importances[idx])\n",
    "plt.xticks(range(len(idx)), top_feats, rotation=60, ha='right')\n",
    "plt.title(\"Random Forest Feature Importance (Top 20) — Combined Dataset\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"rf_importances_combined.png\"), dpi=160, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 20 RF features:\")\n",
    "for name, val in zip(top_feats, importances[idx]):\n",
    "    print(f\"{name:35s} {val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clustering\n",
    "print(\"\\n--- Clustering ---\")\n",
    "\n",
    "scaler_km = StandardScaler()\n",
    "X_all_scaled = scaler_km.fit_transform(X)\n",
    "\n",
    "# K-Means\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "labels_km = kmeans.fit_predict(X_all_scaled)\n",
    "sil_km = silhouette_score(X_all_scaled, labels_km)\n",
    "ari_km = adjusted_rand_score(y, labels_km)\n",
    "print(f\"K-Means (k=2): Silhouette={sil_km:.5f}, ARI={ari_km:.5f}\")\n",
    "\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=15, n_jobs=-1)\n",
    "labels_db = dbscan.fit_predict(X_all_scaled)\n",
    "valid = labels_db != -1\n",
    "if valid.sum() > 1 and len(set(labels_db[valid])) > 1:\n",
    "    sil_db = silhouette_score(X_all_scaled[valid], labels_db[valid])\n",
    "    ari_db = adjusted_rand_score(y[valid], labels_db[valid])\n",
    "else:\n",
    "    sil_db, ari_db = float(\"nan\"), float(\"nan\")\n",
    "unique, counts = np.unique(labels_db, return_counts=True)\n",
    "print(\"DBSCAN clusters:\", dict(zip(unique, counts)))\n",
    "print(f\"DBSCAN (non-noise): Silhouette={sil_db:.5f}, ARI={ari_db:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save metrics table\n",
    "metrics = pd.DataFrame([m_lr, m_svm, m_rf])\n",
    "csv_path = os.path.join(ART_DIR, \"classifier_metrics_combined.csv\")\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "metrics.to_csv(csv_path, index=False)\n",
    "print(\"Saved metrics to:\", csv_path)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93995c35",
   "metadata": {},
   "source": [
    "\n",
    "## Wrap-up\n",
    "\n",
    "- **Best supervised model** is typically **SVM (RBF)** or **constrained Random Forest** on this combined dataset.\n",
    "- ROC curves and feature importances are saved to `artifacts/plots/`.\n",
    "- Metrics table saved to `artifacts/classifier_metrics_combined.csv` for your report appendix.\n",
    "- Clustering results are included for the second ML category requirement; tune DBSCAN's `eps`/`min_samples` if desired.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
